{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_UsingCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11G_KLshLTbv0SpSu78IL2gTPRD-AWlfD",
      "authorship_tag": "ABX9TyOy+hFXs0r0fLAGj+0ZyO5J"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07dtqo7sZHel",
        "colab_type": "text"
      },
      "source": [
        "#Preparing and Exploring Image Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vmXpmaCPWeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozMrSjC3P2rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip '/content/drive/My Drive/Colab Notebooks/Udacity_DL/Dataset/MNIST-Dataset/mnist-in-csv.zip' -d '/content/drive/My Drive/Colab Notebooks/Udacity_DL/Dataset/MNIST-Dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSdw4lI0TfE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Udacity_DL/Dataset/MNIST-Dataset/mnist_train.csv')\n",
        "mnist_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Udacity_DL/Dataset/MNIST-Dataset/mnist_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajgTcPr3UwQF",
        "colab_type": "code",
        "outputId": "10703c36-ade8-430f-b7db-812e537523e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "mnist_train.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>1x1</th>\n",
              "      <th>1x2</th>\n",
              "      <th>1x3</th>\n",
              "      <th>1x4</th>\n",
              "      <th>1x5</th>\n",
              "      <th>1x6</th>\n",
              "      <th>1x7</th>\n",
              "      <th>1x8</th>\n",
              "      <th>1x9</th>\n",
              "      <th>1x10</th>\n",
              "      <th>1x11</th>\n",
              "      <th>1x12</th>\n",
              "      <th>1x13</th>\n",
              "      <th>1x14</th>\n",
              "      <th>1x15</th>\n",
              "      <th>1x16</th>\n",
              "      <th>1x17</th>\n",
              "      <th>1x18</th>\n",
              "      <th>1x19</th>\n",
              "      <th>1x20</th>\n",
              "      <th>1x21</th>\n",
              "      <th>1x22</th>\n",
              "      <th>1x23</th>\n",
              "      <th>1x24</th>\n",
              "      <th>1x25</th>\n",
              "      <th>1x26</th>\n",
              "      <th>1x27</th>\n",
              "      <th>1x28</th>\n",
              "      <th>2x1</th>\n",
              "      <th>2x2</th>\n",
              "      <th>2x3</th>\n",
              "      <th>2x4</th>\n",
              "      <th>2x5</th>\n",
              "      <th>2x6</th>\n",
              "      <th>2x7</th>\n",
              "      <th>2x8</th>\n",
              "      <th>2x9</th>\n",
              "      <th>2x10</th>\n",
              "      <th>2x11</th>\n",
              "      <th>...</th>\n",
              "      <th>27x17</th>\n",
              "      <th>27x18</th>\n",
              "      <th>27x19</th>\n",
              "      <th>27x20</th>\n",
              "      <th>27x21</th>\n",
              "      <th>27x22</th>\n",
              "      <th>27x23</th>\n",
              "      <th>27x24</th>\n",
              "      <th>27x25</th>\n",
              "      <th>27x26</th>\n",
              "      <th>27x27</th>\n",
              "      <th>27x28</th>\n",
              "      <th>28x1</th>\n",
              "      <th>28x2</th>\n",
              "      <th>28x3</th>\n",
              "      <th>28x4</th>\n",
              "      <th>28x5</th>\n",
              "      <th>28x6</th>\n",
              "      <th>28x7</th>\n",
              "      <th>28x8</th>\n",
              "      <th>28x9</th>\n",
              "      <th>28x10</th>\n",
              "      <th>28x11</th>\n",
              "      <th>28x12</th>\n",
              "      <th>28x13</th>\n",
              "      <th>28x14</th>\n",
              "      <th>28x15</th>\n",
              "      <th>28x16</th>\n",
              "      <th>28x17</th>\n",
              "      <th>28x18</th>\n",
              "      <th>28x19</th>\n",
              "      <th>28x20</th>\n",
              "      <th>28x21</th>\n",
              "      <th>28x22</th>\n",
              "      <th>28x23</th>\n",
              "      <th>28x24</th>\n",
              "      <th>28x25</th>\n",
              "      <th>28x26</th>\n",
              "      <th>28x27</th>\n",
              "      <th>28x28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>147</td>\n",
              "      <td>252</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  1x1  1x2  1x3  1x4  1x5  ...  28x23  28x24  28x25  28x26  28x27  28x28\n",
              "0      5    0    0    0    0    0  ...      0      0      0      0      0      0\n",
              "1      0    0    0    0    0    0  ...      0      0      0      0      0      0\n",
              "2      4    0    0    0    0    0  ...      0      0      0      0      0      0\n",
              "3      1    0    0    0    0    0  ...      0      0      0      0      0      0\n",
              "4      9    0    0    0    0    0  ...      0      0      0      0      0      0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppMSIqaTU5Jo",
        "colab_type": "code",
        "outputId": "00a0371d-cc04-46f0-e97d-f02263d1b2cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mnist_train.shape, mnist_test.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 785), (10000, 785))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ucjAlzIVMfs",
        "colab_type": "text"
      },
      "source": [
        "Drop all empty fileds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9o1XFzFU_Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train = mnist_train.dropna()\n",
        "mnist_test = mnist_test.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN9gR8_EVQyG",
        "colab_type": "code",
        "outputId": "8bf0b377-66e2-43b2-9414-f0afc157f98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "random_sel = mnist_train.sample(8)\n",
        "\n",
        "random_sel.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li6v1TY0VfD4",
        "colab_type": "code",
        "outputId": "6192a45f-9b0a-42f3-e14e-5e1a6b7c9dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_features = random_sel.drop('label', axis=1)\n",
        "\n",
        "img_batch = (torch.Tensor(img_features.values/255,)).reshape(-1, 28, 28)\n",
        "\n",
        "img_batch.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvAkShIYWJkX",
        "colab_type": "code",
        "outputId": "8c77bc8b-7a2a-4174-9009-cfa71c06e4c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_batch.unsqueeze(1).shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTupLz7kV6al",
        "colab_type": "code",
        "outputId": "625eaea9-838c-4440-a7dc-4713bf833dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grid = torchvision.utils.make_grid(img_batch.unsqueeze(1), nrow=8)\n",
        "\n",
        "grid.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 242])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR_csR7yWSD5",
        "colab_type": "code",
        "outputId": "93684f72-362d-4770-d546-878a21e8cbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "plt.figure(figsize = (12, 12))\n",
        "\n",
        "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "\n",
        "plt.axis('off')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 241.5, 31.5, -0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Kl-oLeWrWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train_features = mnist_train.drop('label', axis=1)\n",
        "mnist_train_target = mnist_train['label']\n",
        "\n",
        "mnist_test_features = mnist_test.drop('label', axis=1)\n",
        "mnist_test_target = mnist_test['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9YckyApXMox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tensor = torch.tensor(mnist_train_features.values, dtype=torch.float)\n",
        "Y_train_tensor = torch.tensor(mnist_train_target.values, dtype=torch.long)\n",
        "\n",
        "X_test_tensor = torch.tensor(mnist_test_features.values, dtype=torch.float)\n",
        "Y_test_tensor = torch.tensor(mnist_test_target.values, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5dbn6iwXxDD",
        "colab_type": "code",
        "outputId": "bfece0ca-17bb-4b6f-ea8d-2e8bcd4d3796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "X_train_tensor.shape, X_test_tensor.shape, Y_train_tensor.shape, Y_test_tensor.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 784]),\n",
              " torch.Size([10000, 784]),\n",
              " torch.Size([60000]),\n",
              " torch.Size([10000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5NlT4gOYGQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tensor = X_train_tensor.reshape(-1, 1, 28, 28)\n",
        "X_test_tensor = X_test_tensor.reshape(-1, 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdd09RKHY4C9",
        "colab_type": "code",
        "outputId": "4bb99314-cb81-4e53-ed4d-c6dff758a873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "X_train_tensor.shape, X_test_tensor.shape, Y_train_tensor.shape, Y_test_tensor.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 1, 28, 28]),\n",
              " torch.Size([10000, 1, 28, 28]),\n",
              " torch.Size([60000]),\n",
              " torch.Size([10000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vboCptVTZR97",
        "colab_type": "text"
      },
      "source": [
        "#Setting CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mwvjJjeZUPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usbumX2kZdHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_size = 1\n",
        "\n",
        "hid1_size = 16\n",
        "hid2_size = 32\n",
        "\n",
        "out_size = 10\n",
        "\n",
        "k_conv_size = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyXppapRZq2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    \n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_size, hid1_size, k_conv_size),\n",
        "        nn.BatchNorm2d(hid1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2)\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(hid1_size, hid2_size, k_conv_size),\n",
        "        nn.BatchNorm2d(hid2_size),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2)\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Linear(512, out_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    out = self.layer1(x)\n",
        "    print(out.shape)\n",
        "\n",
        "    out = self.layer2(out)\n",
        "    print(out.shape)\n",
        "\n",
        "    out = out.reshape(out.size(0), -1)\n",
        "    print(out.shape)\n",
        "\n",
        "    out = self.fc(out)\n",
        "    print(out.shape)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKsxUmq-cL5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ConvNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzaef9JGcPcj",
        "colab_type": "code",
        "outputId": "7cd77749-23a6-40e2-a717-35ad4d23aeba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajq-opQXc6BW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68ejD96zdCbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tensor = X_train_tensor.to(device)\n",
        "X_test_tensor = X_test_tensor.to(device)\n",
        "Y_train_tensor = Y_train_tensor.to(device)\n",
        "Y_test_tensor = Y_test_tensor.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu8Q5ypydX8D",
        "colab_type": "text"
      },
      "source": [
        "#Training Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsOjX1FedQHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3jkB5YzdwWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "loss_values = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKQG_5Mhd2GG",
        "colab_type": "code",
        "outputId": "c0dca935-837f-444d-e04c-941caf981709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "\n",
        "  outputs = model(X_train_tensor)\n",
        "  loss = criterion(outputs, Y_train_tensor)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(\"Epoch - %d, loss - %0.5f \"%(epoch, loss.item()))\n",
        "  loss_values.append(loss.item())"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 1, loss - 2.54194 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 2, loss - 2.19630 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 3, loss - 1.98693 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 4, loss - 1.81041 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 5, loss - 1.64647 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 6, loss - 1.49797 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 7, loss - 1.36848 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 8, loss - 1.25597 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 9, loss - 1.15655 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 10, loss - 1.06801 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 11, loss - 0.98970 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 12, loss - 0.92058 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 13, loss - 0.85879 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 14, loss - 0.80233 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 15, loss - 0.74996 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 16, loss - 0.70132 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 17, loss - 0.65664 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 18, loss - 0.61620 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 19, loss - 0.58005 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 20, loss - 0.54781 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VCuE1qEegzz",
        "colab_type": "code",
        "outputId": "9330bb55-fb56-4f7f-a831-d8899cf89161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpfWNFDTf5w3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Debwjk2zgInV",
        "colab_type": "code",
        "outputId": "a56798b3-6861-4487-ca15-79947dc79092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  outputs = model(X_test_tensor)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "  y_test = Y_test_tensor.cpu().numpy()\n",
        "  predicted = predicted.cpu()\n",
        "\n",
        "  print(\"Accuracy: \", accuracy_score(predicted, y_test))\n",
        "  print(\"Precision: \", precision_score(predicted, y_test, average=\"weighted\"))\n",
        "  print(\"Recall: \", recall_score(predicted, y_test, average=\"weighted\")) "
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 16, 12, 12])\n",
            "torch.Size([10000, 32, 4, 4])\n",
            "torch.Size([10000, 512])\n",
            "torch.Size([10000, 10])\n",
            "Accuracy:  0.9104\n",
            "Precision:  0.9108746385389\n",
            "Recall:  0.9104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX8kdGlViuA9",
        "colab_type": "text"
      },
      "source": [
        "#HyperParameter Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDjZcCZTi9b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_size = 1\n",
        "\n",
        "hid1_size = 16\n",
        "hid2_size = 32\n",
        "\n",
        "out_size = 10\n",
        "\n",
        "k_conv_size = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byd5mDvrjDxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    \n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_size, hid1_size, k_conv_size),\n",
        "        nn.BatchNorm2d(hid1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2)\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(hid1_size, hid2_size, k_conv_size),\n",
        "        nn.BatchNorm2d(hid2_size),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2)\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Linear(512, out_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    out = self.layer1(x)\n",
        "    print(out.shape)\n",
        "\n",
        "    out = self.layer2(out)\n",
        "    print(out.shape)\n",
        "\n",
        "    out = out.reshape(out.size(0), -1)\n",
        "    print(out.shape)\n",
        "\n",
        "    out = self.fc(out)\n",
        "    print(out.shape)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwJ3eMBgjKIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ConvNet()\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxrg-EayheHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI9mejS7ixkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 70\n",
        "loss_values = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03lTZPzi1RX",
        "colab_type": "code",
        "outputId": "8a153f56-df3d-4a78-95ff-830aa4cc4f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "\n",
        "  outputs = model(X_train_tensor)\n",
        "  loss = criterion(outputs, Y_train_tensor)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(\"Epoch - %d, loss - %0.5f \"%(epoch, loss.item()))\n",
        "  loss_values.append(loss.item())"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 1, loss - 2.57530 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 2, loss - 2.66418 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 3, loss - 2.00569 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 4, loss - 1.25484 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 5, loss - 1.23943 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 6, loss - 1.13569 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 7, loss - 0.79685 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 8, loss - 0.57155 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 9, loss - 0.57595 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 10, loss - 0.58749 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 11, loss - 0.51754 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 12, loss - 0.42172 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 13, loss - 0.36081 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 14, loss - 0.34024 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 15, loss - 0.33878 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 16, loss - 0.32964 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 17, loss - 0.30653 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 18, loss - 0.27998 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 19, loss - 0.26083 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 20, loss - 0.25070 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 21, loss - 0.24320 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 22, loss - 0.23231 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 23, loss - 0.21827 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 24, loss - 0.20535 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 25, loss - 0.19696 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 26, loss - 0.19278 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 27, loss - 0.18934 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 28, loss - 0.18320 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 29, loss - 0.17392 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 30, loss - 0.16400 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 31, loss - 0.15623 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 32, loss - 0.15147 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 33, loss - 0.14868 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 34, loss - 0.14615 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 35, loss - 0.14280 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 36, loss - 0.13857 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 37, loss - 0.13398 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 38, loss - 0.12958 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 39, loss - 0.12569 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 40, loss - 0.12240 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 41, loss - 0.11973 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 42, loss - 0.11744 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 43, loss - 0.11512 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 44, loss - 0.11249 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 45, loss - 0.10965 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 46, loss - 0.10696 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 47, loss - 0.10461 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 48, loss - 0.10249 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 49, loss - 0.10032 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 50, loss - 0.09800 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 51, loss - 0.09572 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 52, loss - 0.09376 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 53, loss - 0.09214 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 54, loss - 0.09066 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 55, loss - 0.08911 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 56, loss - 0.08744 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 57, loss - 0.08575 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 58, loss - 0.08412 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 59, loss - 0.08261 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 60, loss - 0.08118 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 61, loss - 0.07984 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 62, loss - 0.07858 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 63, loss - 0.07735 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 64, loss - 0.07612 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 65, loss - 0.07487 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 66, loss - 0.07366 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 67, loss - 0.07253 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 68, loss - 0.07147 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 69, loss - 0.07045 \n",
            "torch.Size([60000, 16, 12, 12])\n",
            "torch.Size([60000, 32, 4, 4])\n",
            "torch.Size([60000, 512])\n",
            "torch.Size([60000, 10])\n",
            "Epoch - 70, loss - 0.06944 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQwuCrKxmXUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6c388297-e3c2-4563-f6f0-1c8cfb52c0ab"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgVo0ll6jUNg",
        "colab_type": "code",
        "outputId": "41550a7e-2640-4749-fbaa-d404beb2f0a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  outputs = model(X_test_tensor)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "  y_test = Y_test_tensor.cpu().numpy()\n",
        "  predicted = predicted.cpu()\n",
        "\n",
        "  print(\"Accuracy: \", accuracy_score(predicted, y_test))\n",
        "  print(\"Precision: \", precision_score(predicted, y_test, average=\"weighted\"))\n",
        "  print(\"Recall: \", recall_score(predicted, y_test, average=\"weighted\")) "
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 16, 12, 12])\n",
            "torch.Size([10000, 32, 4, 4])\n",
            "torch.Size([10000, 512])\n",
            "torch.Size([10000, 10])\n",
            "Accuracy:  0.9785\n",
            "Precision:  0.9787438592965524\n",
            "Recall:  0.9785\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}